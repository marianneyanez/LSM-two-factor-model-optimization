{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import math\n",
    "import numpy as np\n",
    "from colorama import Fore, Back, Style\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from mlinsights.mlmodel import PiecewiseRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining risk attitude and regressor to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_attitude='Neutral'\n",
    "regressor='XGB'\n",
    "Rho=800   # Risk tolerance\n",
    "risk_attitude='risk_averse'+str(Rho)\n",
    "regressor='XGB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading MonteCarlo sampling of priors\n",
    "Reading fixed 10.000 MC samples previously exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MC = 10000 # Number of MC samples\n",
    "FieldLifeTime = 50 # Number of years for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path=\"C:/Users/maria/OneDrive - Universitetet i Stavanger/Master thesis/Dataframes_from_Python/\" # Path in personal laptop\n",
    "\n",
    "OOIP_prior=np.loadtxt(Path+\"OOIP_prior\",delimiter=\",\")\n",
    "E_inf_Phase1_prior=np.loadtxt(Path+\"E_inf_Phase1_prior\",delimiter=\",\")\n",
    "Tau_Phase1_prior=np.loadtxt(Path+\"Tau_Phase1_prior\",delimiter=\",\")\n",
    "dE_inf_Phase2_prior=np.loadtxt(Path+\"dE_inf_Phase2_prior\",delimiter=\",\")\n",
    "Tau_Phase2_prior=np.loadtxt(Path+\"Tau_Phase2_prior\",delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing matrixes\n",
    "Recovery_Phase1_real_time = np.zeros([N_MC,FieldLifeTime]) \n",
    "Recovery_Phase1_real_EndTime = np.zeros([N_MC,1])\n",
    "Recovery_Phase2_real_time = np.zeros([N_MC,1]) \n",
    "Recovery_Phase1n2_real_time = np.zeros([N_MC,FieldLifeTime])\n",
    "Recovery_Phase1n2_real_time_ShiftTime = np.zeros([N_MC,FieldLifeTime,FieldLifeTime+1])\n",
    "Rate_Phase1n2_real_time_ShiftTime = np.zeros([N_MC,FieldLifeTime,FieldLifeTime+1])\n",
    "\n",
    "ER1_0 = 0 # Primary Recovery Factor at t=0\n",
    "\n",
    "# For calculations below consider 'time' and 't' as positions in time (year) within the production lifetime for each recovery phase (primary and secondary). Assumed to be at the start of the year \n",
    "\n",
    "for i_MC in range(N_MC):\n",
    "    \n",
    "            \n",
    "    for time in range(1,FieldLifeTime+1): # This is the time shift in columns. This representes the potential lengths of the Primary Recovery\n",
    "                              \n",
    "        Recovery_Phase1_real_time[i_MC,time-1] = ER1_0+np.multiply((E_inf_Phase1_prior[i_MC]-ER1_0),(1-np.exp(-time/Tau_Phase1_prior[i_MC]))) # np.multiply guarantees element-wise multiplication\n",
    "                \n",
    "        if time == 1:  \n",
    "            Recovery_Phase1_real_EndTime[i_MC] = ER1_0 \n",
    "        else:\n",
    "            Recovery_Phase1_real_EndTime[i_MC] = Recovery_Phase1_real_time[i_MC,time-2] # Since the ERs are set at the start of each year, the end of the phase 1 should be the start of the previous year\n",
    "                 \n",
    "        Recovery_Phase2_real_time[i_MC] = Recovery_Phase1_real_EndTime[i_MC] +np.multiply(dE_inf_Phase2_prior[i_MC],(1-np.exp(-1/Tau_Phase2_prior[i_MC])))\n",
    "             \n",
    "        \n",
    "     # Now we compute the possible combinations of time and t\n",
    "        \n",
    "        \n",
    "        for t in range(1,FieldLifeTime+1): # This is the time shift in rows. This representes the potential positions of the Secondary Recovery\n",
    "                   \n",
    "            if t<time:  # Positions in time that fall within the primary recovery. Hence, we store the ER of primary recovery (previously calculated)\n",
    "                Recovery_Phase1n2_real_time[i_MC,t-1] = Recovery_Phase1_real_time[i_MC,t-1]\n",
    "                    \n",
    "            else:\n",
    "                if t==time: # At this position in time, secondary recovery is just starting in that year. Hence, we store the info of secondary recovery when only lasts 1 year (previously calculated)\n",
    "                    Recovery_Phase1n2_real_time[i_MC,t-1] = Recovery_Phase2_real_time[i_MC]\n",
    "                else:\n",
    "                    # Cases for secondary recovery lasting more than 1 year, which brings now multiple combinations\n",
    "                    \n",
    "                    Recovery_Phase1n2_real_time[i_MC,t-1] = Recovery_Phase1_real_EndTime[i_MC] +np.multiply(dE_inf_Phase2_prior[i_MC],(1-np.exp(-(t-time+1)/Tau_Phase2_prior[i_MC])))\n",
    "                    \n",
    "            # The matrix below compiles now all the recovery factors at the respective combination of primary and secondary production\n",
    "            \n",
    "            Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-1,time-1] = Recovery_Phase1n2_real_time[i_MC,t-1] # This t-variable matrix fills into a complete t,time-variable matrix, for each time\n",
    "            Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-1,FieldLifeTime+0] = Recovery_Phase1_real_time[i_MC,t-1] # Case of only primary recovery (time = FieldLifeTime), cuando el length del primary recovery os the fieldlifetime\n",
    "            \n",
    "\n",
    "# Computation of the flow rates\n",
    "    \n",
    "            if t==1: \n",
    "                Rate_Phase1n2_real_time_ShiftTime[i_MC,t-1,time-1] = np.multiply(OOIP_prior[i_MC],Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-1,time-1])\n",
    "                Rate_Phase1n2_real_time_ShiftTime[i_MC,t-1,FieldLifeTime+0] =np.multiply(OOIP_prior[i_MC],Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-1,FieldLifeTime+0])\n",
    " \n",
    "            else: \n",
    "                Rate_Phase1n2_real_time_ShiftTime[i_MC,t-1,time-1] = np.multiply(OOIP_prior[i_MC],(Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-1,time-1]-Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-2,time-1]))\n",
    "                Rate_Phase1n2_real_time_ShiftTime[i_MC,t-1,FieldLifeTime+0] = np.multiply(OOIP_prior[i_MC],(Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-1,FieldLifeTime+0]-Recovery_Phase1n2_real_time_ShiftTime[i_MC,t-2,FieldLifeTime+0]))\n",
    "\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the measurement error and the measured oil production rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding some error to the mean and std\n",
    "ErrorMean4Rate_Pct = 0\n",
    "ErrorSD4Rate_Pct = 0.10 \n",
    "\n",
    "ErrorSD_Matrix = np.multiply(ErrorSD4Rate_Pct,Rate_Phase1n2_real_time_ShiftTime)  \n",
    "\n",
    "# Fixing the measurement error for all the tests run with this code\n",
    "# np.random.RandomState() constructs a random number generator. To be consistent with tests, we create a specific RandomState and draw to pseudorandom numbers in a reproducible way.\n",
    "random_state=np.random.RandomState(0)\n",
    "\n",
    "# \"Observed\" rates (error incorporated) sampling\n",
    "ObsRate_Phase1n2_real_time_ShiftTime = random_state.normal(Rate_Phase1n2_real_time_ShiftTime,ErrorSD_Matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Cashflow and NPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CashFlow = np.zeros([N_MC,FieldLifeTime])\n",
    "DisCashFlow = np.zeros([N_MC,FieldLifeTime])\n",
    "DisCashFlow_ShiftTime = np.zeros([N_MC,FieldLifeTime,FieldLifeTime+1])\n",
    "NPV_reals = np.zeros([N_MC,1])\n",
    "NPVtable_LTPhase1_LTPhase2_real = np.zeros([FieldLifeTime+1,FieldLifeTime+1,N_MC])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Economic parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OilPrice = 50\n",
    "Capex_Phase1 = 50\n",
    "Capex_Phase2After1 = 40\n",
    "Capex_Phase2No1 = 75\n",
    "Opex_Phase1 = 20\n",
    "Opex_Phase2 = 30\n",
    "DisRate = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPEX is deducted every year, depending on which recovery mechanism is being used\n",
    "# CAPEX is only deducted at the year when the recovery phase is started\n",
    "\n",
    "for t in range(1,FieldLifeTime+1):\n",
    "    for time in range(1,FieldLifeTime+2):\n",
    "        \n",
    "     \n",
    "        if t == time: # At this position in time, secondary recovery is just starting in that year\n",
    "            if time == 1: # First year. Case of secondary recovery without having primary recovery. We subtract CAPEX for secondary recovery at this start\n",
    "                CashFlow[:,t-1] = np.multiply(OilPrice,ObsRate_Phase1n2_real_time_ShiftTime[:,t-1,time-1]) - Opex_Phase2 - Capex_Phase2No1 \n",
    "                DisCashFlow[:,t-1] = np.divide(CashFlow[:,t-1],np.power((1+DisRate),t))\n",
    "            else: # Case of secondary recovery after primary recovery\n",
    "                CashFlow[:,t-1] = np.multiply(OilPrice,ObsRate_Phase1n2_real_time_ShiftTime[:,t-1,time-1]) - Opex_Phase2 - Capex_Phase2After1 \n",
    "                DisCashFlow[:,t-1] = np.divide(CashFlow[:,t-1],np.power((1+DisRate),t))\n",
    "        else:\n",
    "            if t<time:  # Here are positions in time during primary recovery\n",
    "                if t == 1: # First year. We subtract CAPEX for primary production at this start\n",
    "                    CashFlow[:,t-1] = np.multiply(OilPrice,ObsRate_Phase1n2_real_time_ShiftTime[:,t-1,time-1]) - Opex_Phase1 - Capex_Phase1\n",
    "                    DisCashFlow[:,t-1] = np.divide(CashFlow[:,t-1],np.power((1+DisRate),t))\n",
    "                else: # Any different to first year. We don't discount CAPEX\n",
    "                    CashFlow[:,t-1] = np.multiply(OilPrice,ObsRate_Phase1n2_real_time_ShiftTime[:,t-1,time-1]) - Opex_Phase1 \n",
    "                    DisCashFlow[:,t-1] = np.divide(CashFlow[:,t-1],np.power((1+DisRate),t))\n",
    "            else: # Here are positions in time after primary recovery. Means we are at secondary recovery (and has already started), hence, we dont discount CAPEX\n",
    "                CashFlow[:,t-1] = np.multiply(OilPrice,ObsRate_Phase1n2_real_time_ShiftTime[:,t-1,time-1]) - Opex_Phase2  \n",
    "                DisCashFlow[:,t-1] = np.divide(CashFlow[:,t-1],np.power((1+DisRate),t))\n",
    "\n",
    "        # This matrix contains the cash flows for each production combination \n",
    "        DisCashFlow_ShiftTime[:,t-1,time-1] = DisCashFlow[:,t-1] \n",
    "        \n",
    "       # Now the cumulative NPVs are computed \n",
    "        if time == 1:\n",
    "            NPV_reals = np.sum(DisCashFlow_ShiftTime[:,0:t,time-1],axis=1) \n",
    "            NPVtable_LTPhase1_LTPhase2_real[time-1,t+0,:] = NPV_reals[:] \n",
    "        \n",
    "        else:\n",
    "            if time==FieldLifeTime+1:\n",
    "                NPV_reals = np.sum(DisCashFlow_ShiftTime[:,0:FieldLifeTime,time-1],axis=1) \n",
    "                NPVtable_LTPhase1_LTPhase2_real[time-1,0,:] = NPV_reals[:] \n",
    "            else:\n",
    "                if t==time: # At this position in time, secondary recovery is just starting in that year\n",
    "                    NPV_reals = np.sum(DisCashFlow_ShiftTime[:,0:time,time-1],axis=1) \n",
    "                    NPVtable_LTPhase1_LTPhase2_real[time-1,1,:] = NPV_reals[:]\n",
    "                else:\n",
    "                    if t<time:\n",
    "                        NPV_reals = np.sum(DisCashFlow_ShiftTime[:,0:time-1,time-1],axis=1) \n",
    "                        NPVtable_LTPhase1_LTPhase2_real[time-1,0,:] = NPV_reals[:]\n",
    "                    else:\n",
    "                        NPV_reals = np.sum(DisCashFlow_ShiftTime[:,0:t,time-1],axis=1) \n",
    "                        NPVtable_LTPhase1_LTPhase2_real[time-1,t-time+1,:] = NPV_reals[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorporating Risk Attitude - Utility function and transformation of NPVs\n",
    "Calculation of utilities from NPVs. \n",
    "For simplicity of the code, the names of the utilities have been kept as NPV.\n",
    "Return to CEs is performed at the end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=1-np.exp(-NPVtable_LTPhase1_LTPhase2_real/Rho) # Utility function for risk-averse case\n",
    "NPVtable_LTPhase1_LTPhase2_real=u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determination of DWPI, and VOPI, DWOI, VWOI\n",
    "\n",
    "This section determines the Decision Without Information and Decision With Perfect Value Without Information \n",
    "and Value of Perfect Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Phase1n2LifeTime = np.sum(range(0,FieldLifeTime+2)) \n",
    "NPVvector_1real = np.zeros([N_Phase1n2LifeTime,3])\n",
    "NPVmatrix_reals = np.zeros([N_Phase1n2LifeTime,N_MC])\n",
    "Sum_NPVvector_1real = np.zeros([N_Phase1n2LifeTime,1])\n",
    "meanNPVvector = np.zeros([N_Phase1n2LifeTime,3])\n",
    "NPV_element_vector = np.zeros([FieldLifeTime+1,FieldLifeTime+1])\n",
    "Phase1n2LifeTimeTable = np.zeros([N_Phase1n2LifeTime,2])\n",
    "\n",
    "VWPI_real = np.zeros([N_MC,1])\n",
    "DWPI_Phase1LifeTime_real = np.zeros([N_MC,1])\n",
    "DWPI_Phase2LifeTime_real = np.zeros([N_MC,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1,FieldLifeTime+1):\n",
    "    for time in range(1,FieldLifeTime+2):\n",
    "        NPV_element_vector[time-1,t+0] = t\n",
    "        if time > 1:\n",
    "            NPV_element_vector[time-1,FieldLifeTime-time+2:FieldLifeTime+1] = FieldLifeTime+1 \n",
    "        else:\n",
    "            NPV_element_vector[time-1,t+0] = t\n",
    "        \n",
    "([col_NPV_element,row_NPV_element])=np.where(NPV_element_vector[:,:] < FieldLifeTime+1)   \n",
    "col_NPV_element = col_NPV_element\n",
    "row_NPV_element =row_NPV_element "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1,N_Phase1n2LifeTime+1):\n",
    "    NPVvector_1real[k-1,0] = col_NPV_element[k-1] \n",
    "    NPVvector_1real[k-1,1] = row_NPV_element[k-1]\n",
    "    meanNPVvector[k-1,0] = col_NPV_element[k-1]\n",
    "    meanNPVvector[k-1,1] = row_NPV_element[k-1]\n",
    "\n",
    "for i_MC in range(N_MC):\n",
    "    for k in range(1,N_Phase1n2LifeTime+1):\n",
    "                \n",
    "        NPVvector_1real[k-1,2] =NPVtable_LTPhase1_LTPhase2_real[col_NPV_element[k-1],row_NPV_element[k-1],i_MC]       \n",
    "        NPVmatrix_reals[k-1,i_MC] = NPVvector_1real[k-1,2]\n",
    "        \n",
    "        # For perfect information we identify the maximum NPV , among the t and time combinations, for a single realization        \n",
    "        VWPI_real[i_MC],DWPI_idx = NPVvector_1real.max(axis=0)[2],NPVvector_1real.argmax(axis=0)[2]                \n",
    "        DWPI_Phase1LifeTime_real[i_MC] = NPVvector_1real[DWPI_idx,0]\n",
    "        DWPI_Phase2LifeTime_real[i_MC] = NPVvector_1real[DWPI_idx,1]\n",
    "        \n",
    "# This calculates the Mean NPV among the realizations, for each t and time combination\n",
    "meanNPV = NPVmatrix_reals.mean(axis=1)\n",
    "\n",
    "for k in range(1,N_Phase1n2LifeTime+1):    \n",
    "    meanNPVvector[k-1,2] = meanNPV[k-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercising the decision policy without information\n",
    "# Choose the maximum average NPV (average NPV has been calculated over all realizations for each combination of t and time) \n",
    "EVWOI,DWOI_idx = meanNPVvector.max(axis=0)[2],meanNPVvector.argmax(axis=0)[2] \n",
    "DWOI_Phase1LifeTime = col_NPV_element[DWOI_idx] \n",
    "DWOI_Phase2LifeTime = row_NPV_element[DWOI_idx]\n",
    "DWOI_LifeTime = DWOI_Phase1LifeTime + DWOI_Phase2LifeTime\n",
    "DWPI_LifeTime_real = DWPI_Phase1LifeTime_real + DWPI_Phase2LifeTime_real\n",
    "Phase1n2LifeTimeTable[:,0] = meanNPVvector[:,0]\n",
    "Phase1n2LifeTimeTable[:,1] = meanNPVvector[:,1]\n",
    "\n",
    "# Exercising the decision policy with Perfect information\n",
    "# Calculate the average of the maximum NPVs that had been calculated for each realization (maximum NPV given by the time and t combinations for each realization) \n",
    "EVWPI = np.mean(VWPI_real) \n",
    "VOPI = EVWPI - EVWOI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSM approach using XGB\n",
    "\n",
    "This section determines the optimum switch time to secondary recovery, and also the optimum stopping time of secondary recovery.\n",
    "Regression analysis is performed, as part of the LSM workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining optimal stopping time for each potential switch time\n",
    "We first determine the optimum stopping time of secondary recovery, for each possible switch time.\n",
    "The NPV corresponding to the optimal stopping time is recorded into the PathTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRDM_Shift_Stop_OptNPV_real = np.zeros([N_MC,1])\n",
    "\n",
    "PathTable = np.zeros([N_MC,FieldLifeTime+1])\n",
    "PathTable[:,-1] = NPVtable_LTPhase1_LTPhase2_real[FieldLifeTime+0,0,:]\n",
    "Phase2_StopTime_real_Phase1LifeTime = np.zeros([N_MC,FieldLifeTime+1])\n",
    "\n",
    "for k_Shift_time in range(1,FieldLifeTime+1):\n",
    "    NPV_2Phases_matrix = np.zeros([N_MC,k_Shift_time+1]) \n",
    "    \n",
    "    for k_Stop_time in range(1,k_Shift_time+2):\n",
    "        # This starts the analysis at year time=50\n",
    "        NPV_2Phases_matrix[:,k_Stop_time-1] = NPVtable_LTPhase1_LTPhase2_real[FieldLifeTime-k_Shift_time+0,k_Stop_time-1,:] \n",
    "           \n",
    "    for k_StopTime in range(1,k_Shift_time+1):\n",
    "        if k_StopTime == 1:\n",
    "            x_data_stop_SRDM = ObsRate_Phase1n2_real_time_ShiftTime[:,0:FieldLifeTime-k_StopTime,FieldLifeTime-k_Shift_time+0] \n",
    "            X_stop_SRDM = np.concatenate((np.ones([N_MC,1]), x_data_stop_SRDM), axis=1) \n",
    "            y_data_stop_matrix = np.column_stack((NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+0],NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+1]))\n",
    "            \n",
    "            # We compare the ENPVS of two consecutive years, and store them in the SRDM_Shift matrix\n",
    "            # The assesement is done going year by year backwards in time\n",
    "            #Stop_value = np.max(np.column_stack(((xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+0])).predict(X_stop_SRDM),(xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+1])).predict(X_stop_SRDM))), axis=1)\n",
    "            Stop_idx = np.argmax(np.column_stack(((xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+0])).predict(X_stop_SRDM),(xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+1])).predict(X_stop_SRDM))), axis=1)\n",
    "              # Stop_value is the Optimum ENPV, however we only need the index at which it sits, to extract the corresponding NPV\n",
    "                          \n",
    "            for i_MC in range(N_MC):\n",
    "                # This is the actual NPV to be stored as per highest ENPV\n",
    "                # This delivers a single optimum stopping time per realization, which then feeds into the Pathtable\n",
    "                SRDM_Shift_Stop_OptNPV_real[i_MC,0] = y_data_stop_matrix[i_MC,Stop_idx[i_MC]]\n",
    "        else:\n",
    "            x_data_stop_SRDM = ObsRate_Phase1n2_real_time_ShiftTime[:,0:FieldLifeTime-k_StopTime,FieldLifeTime-k_Shift_time+0] \n",
    "            X_stop_SRDM = np.concatenate((np.ones([N_MC,1]), x_data_stop_SRDM), axis=1)\n",
    "            y_data_stop_matrix = np.column_stack((NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+0],SRDM_Shift_Stop_OptNPV_real[:,0]))\n",
    "            #Stop_value = np.max(np.column_stack(((xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+0])).predict(X_stop_SRDM),(xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, SRDM_Shift_Stop_OptNPV_real[:,0])).predict(X_stop_SRDM))), axis=1)\n",
    "            Stop_idx = np.argmax(np.column_stack(((xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, NPV_2Phases_matrix[:,k_Shift_time-k_StopTime+0])).predict(X_stop_SRDM),(xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X_stop_SRDM, SRDM_Shift_Stop_OptNPV_real[:,0])).predict(X_stop_SRDM))), axis=1)\n",
    "            # Stop_value is the Optimum ENPV, however we only need the index at which it sits, to extract the corresponding NPV\n",
    "           \n",
    "            \n",
    "            for i_MC in range(N_MC):\n",
    "                SRDM_Shift_Stop_OptNPV_real[i_MC,0] = y_data_stop_matrix[i_MC,Stop_idx[i_MC]]\n",
    "                \n",
    "    for i_MC in range(N_MC):\n",
    "        # This is the actual NPV to be stored as per highest ENPV, for each realization\n",
    "        PathTable[i_MC,FieldLifeTime-k_Shift_time+0] = SRDM_Shift_Stop_OptNPV_real[i_MC,0]\n",
    "        \n",
    "        for k_Stop_time in range(1,k_Shift_time+2):\n",
    "            if SRDM_Shift_Stop_OptNPV_real[i_MC,0] == NPV_2Phases_matrix[i_MC,k_Stop_time-1]:\n",
    "                Phase2_StopTime_real_Phase1LifeTime[i_MC,FieldLifeTime-k_Shift_time+0] =k_Stop_time-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimum switch time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_data_continuation = np.zeros([N_MC,1])\n",
    "y_data_shift = np.zeros([N_MC,1])\n",
    "y_reg_continuation = np.zeros([N_MC,1])\n",
    "y_reg_shift = np.zeros([N_MC,1])\n",
    "x_data = ObsRate_Phase1n2_real_time_ShiftTime[:,:,FieldLifeTime+0]\n",
    "\n",
    "ValueTable = np.zeros([N_MC,FieldLifeTime+1])\n",
    "ValueTable[:,-1] = PathTable[:,-1] \n",
    "SRDM_DecisionTable = np.zeros([N_MC,FieldLifeTime+1])\n",
    "SRDM_DecisionTable[:,-1] = 1\n",
    "\n",
    "for k_Shift_time in range(1,FieldLifeTime+1):\n",
    "    X = np.concatenate((np.ones([N_MC,1]),x_data[:,0:FieldLifeTime-k_Shift_time]),axis=1) \n",
    "    # Now we compare NPVs from continue with primary recovery with switch to secondary recovery, given its optimum stopping time (stored in the Pathtable for each switch year)\n",
    "    # Then optimum option is compared withn next switch option in time\n",
    "    y_data_shift = PathTable[:,FieldLifeTime-k_Shift_time+0] \n",
    "    y_reg_shift= xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X, y_data_shift).predict(X)\n",
    "    y_data_continuation= ValueTable[:,FieldLifeTime-k_Shift_time+1] \n",
    "    y_reg_continuation =xgb.XGBRegressor(max_depth = 3, eta = 0.1325, subsample = 0.875).fit(X, y_data_continuation).predict(X)\n",
    "    ENPVTable_Comparison =np.column_stack((y_reg_shift,y_reg_continuation))\n",
    "    NPV_SRDM = np.column_stack((y_data_shift, y_data_continuation))\n",
    "    ENPV_SRDM = np.max(ENPVTable_Comparison,axis=1)\n",
    "    ENPV_SRDM_idx=np.argmax(ENPVTable_Comparison,axis=1)\n",
    "        \n",
    "   \n",
    "    for i_MC in range(N_MC):\n",
    "        ValueTable[i_MC,FieldLifeTime-k_Shift_time+0] = NPV_SRDM[i_MC,ENPV_SRDM_idx[i_MC]]\n",
    "        \n",
    "        if y_reg_continuation[i_MC] > y_reg_shift[i_MC]:\n",
    "            SRDM_DecisionTable[i_MC,FieldLifeTime-k_Shift_time+0] = 0\n",
    "        else:\n",
    "            SRDM_DecisionTable[i_MC,FieldLifeTime-k_Shift_time+0] = 1\n",
    "            \n",
    "        \n",
    "ShiftValue = PathTable[:,0]\n",
    "ExpShiftValue = np.mean(ShiftValue)\n",
    "\n",
    "ContinuationValue = ValueTable[:,0]\n",
    "ExpContinuationValue = np.mean(ContinuationValue)\n",
    "EVWII = ExpContinuationValue\n",
    "VOI = EVWII - EVWOI\n",
    "VOI_over_EVWOI_pct = VOI/EVWOI*100\n",
    "\n",
    "DWI_Phase1LifeTime_idx = np.argmax(SRDM_DecisionTable,axis=1)\n",
    "DWI_Phase1LifeTime = DWI_Phase1LifeTime_idx \n",
    "\n",
    "DWI_Phase2LifeTime = np.zeros([N_MC,1])\n",
    "\n",
    "\n",
    "for i_MC in range(N_MC):\n",
    "    Phase1LifeTime_idx_real = DWI_Phase1LifeTime_idx[i_MC] \n",
    "    DWI_Phase2LifeTime[i_MC] = Phase2_StopTime_real_Phase1LifeTime[i_MC,Phase1LifeTime_idx_real]\n",
    "    \n",
    "DWI_LifeTime = np.add(np.array(DWI_Phase1LifeTime),np.array(DWI_Phase2LifeTime).T).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return to CEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse utility function for risk-averse case\n",
    "\n",
    "CEWPI=-Rho*(np.log((1-EVWPI)))\n",
    "CEWOI=-Rho*(np.log((1-EVWOI)))\n",
    "VOPI_Return_to_CE = CEWPI - CEWOI\n",
    "CEWII=-Rho*(np.log((1-EVWII)))\n",
    "VOI_Return_to_CE = CEWII - CEWOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing final results\n",
    "\n",
    "print('CEWOI=',np.round(CEWOI,4))\n",
    "print('CEWPI=',np.round(CEWPI,4))\n",
    "print('VOPI=',np.round(VOPI_Return_to_CE,4))\n",
    "print('CEWII=',np.round(CEWII,4))\n",
    "print('VOI=',np.round(VOI_Return_to_CE,4))\n",
    "print('DWI_LifeTime=',DWI_LifeTime)\n",
    "print(\"Decision without information for Primary recovery length is \" ,DWOI_Phase1LifeTime, \"years\")\n",
    "print(\"Decision without information for Secondary recovery length is \" ,DWOI_Phase2LifeTime, \"years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting final results for further analysis\n",
    "\n",
    "np.savetxt(Path+\"20230208_Fixed_error_measurement_decisions/20230208_Decisions_\"+risk_attitude+\"_\"+regressor+\"_Fixed_error_10000real_Lifetime_Phase1\", DWI_Phase1LifeTime, delimiter=\",\")\n",
    "np.savetxt(Path+\"20230208_Fixed_error_measurement_decisions/20230208_Decisions_\"+risk_attitude+\"_\"+regressor+\"_Fixed_error_10000real_Lifetime_Phase2\", DWI_Phase2LifeTime, delimiter=\",\")\n",
    "np.savetxt(Path+\"20230208_Fixed_error_measurement_decisions/20230208_Decisions_\"+risk_attitude+\"_\"+regressor+\"_DWOI_Lifetime_both_Phases_1and_2\", np.column_stack((DWOI_Phase1LifeTime,DWOI_Phase2LifeTime)),delimiter=\",\")\n",
    "np.savetxt(Path+\"20230208_Fixed_error_measurement_decisions/20230208_Values_\"+risk_attitude+\"_\"+regressor+\"_CEWOI_CEWII_VOI\", np.column_stack((CEWOI,CEWII,VOI_Return_to_CE)),delimiter=\",\")\n",
    "\n",
    "# Average DWII , not rounded \n",
    "np.savetxt(Path+\"20230208_Fixed_error_measurement_decisions/20230208_Decisions_\"+risk_attitude+\"_\"+regressor+\"_Average_DWII_Lifetime_both_Phases_1and_2\", np.column_stack((np.mean(DWI_Phase1LifeTime),np.mean(DWI_Phase2LifeTime))),delimiter=\",\")\n",
    "\n",
    "# Final utilities\n",
    "np.savetxt(Path+\"20230208_Fixed_error_measurement_decisions/20230208_Final_utilities_\"+risk_attitude+\"_\"+regressor+\"_Fixed_error_10000real\", ContinuationValue, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
